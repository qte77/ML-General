{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "#assert sys.version_info >= (3, 5)\n",
    "\n",
    "#h5py error: \"We will have people working on making TF work with\n",
    "#h5py >= 3 in the future, but this will only land in TF 2.5 or later.\"\n",
    "#https://github.com/keras-team/keras/issues/14265\n",
    "#https://github.com/tensorflow/tensorflow/issues/44467\n",
    "#versions: 'h5py < 3.0.0', 'h5py==2.10.0'\n",
    "!{sys.executable} -m pip install 'h5py < 3.0.0'\n",
    "import h5py\n",
    "#h5py.__version__\n",
    "\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "#assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "#assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"ann\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = sys.version_info\n",
    "print(\"sys:\\t %s.%s.%s\" % (sv.major, sv.minor, sv.micro))\n",
    "print(\"skl:\\t\", sklearn.__version__)\n",
    "print(\"tf:\\t\", tf.__version__)\n",
    "print(\"k:\\t\", keras.__version__)\n",
    "print(\"np:\\t\", np.__version__)\n",
    "print(\"h5:\\t\", h5py.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "#https://en.wikipedia.org/wiki/Early_stopping#Early_stopping_based_on_cross-validation\n",
    "#https://www.javacodemonk.com/difference-between-loss-accuracy-validation-loss-validation-accuracy-in-keras-ff358faa\n",
    "#https://docs.paperspace.com/machine-learning/wiki/accuracy-and-loss\n",
    "#https://keras.io/guides/training_with_built_in_methods/\n",
    "#https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
    "#https://keras.io/api/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "#Validation on a holdout set generated from the original training data\n",
    "#Evaluation on the test data\n",
    "#https://keras.io/guides/training_with_built_in_methods/\n",
    "(X_train_o, y_train_o), (X_test_o, y_test_o) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data (these are NumPy arrays)\n",
    "X_train = X_train_o.reshape(-1, 784).astype(\"float32\") / 255.0\n",
    "X_test = X_test_o.reshape(-1, 784).astype(\"float32\") / 255.0\n",
    "\n",
    "y_train = y_train_o.astype(\"float32\")\n",
    "y_test = y_test_o.astype(\"float32\")\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "X_valid = X_train[-10000:]\n",
    "y_valid = y_train[-10000:]\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=2, n_neurons=30,learning_rate=3e-3,input_dim=784):\n",
    "    model = keras.models.Sequential()\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, input_dim=input_dim, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(n_neurons, input_dim=input_dim)), #activation=\"softmax\"))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=[\"sparse_categorical_crossentropy\"],\n",
    "                  optimizer=\"sgd\",\n",
    "                  metrics=[\"acc\"]) #categorical_accuracy\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/guides/writing_your_own_callbacks/\n",
    "#https://github.com/keras-team/keras/issues/2548\n",
    "#TODO stop RandomizedSearchCV not just epoch\n",
    "class EarlyStoppingAtMode(keras.callbacks.Callback):\n",
    "    \"\"\"Stop training when the mode (loss, acc) is at its min/max.\n",
    "\n",
    "Arguments:\n",
    "    test_data\n",
    "    mode\n",
    "    threshold\n",
    "    patience\n",
    "  \"\"\"\n",
    "\n",
    "    def __init__(self, test_data, mode=\"loss\", threshold=0.99, patience=0):\n",
    "        super(EarlyStoppingAtMode, self).__init__()\n",
    "        self.test_data = test_data\n",
    "        self.mode = mode\n",
    "        self.threshold = threshold\n",
    "        self.patience = patience\n",
    "        \n",
    "        self.wait = 0\n",
    "        self.best_weights = None\n",
    "        if self.mode == \"loss\":\n",
    "            self.best = np.Inf\n",
    "        elif self.mode == \"acc\":\n",
    "            self.best = -np.Inf\n",
    "        else:\n",
    "            self.mode = 0\n",
    "        # The epoch the training stops at.\n",
    "        self.stopped_epoch = 0\n",
    "\n",
    "    #not suitable for RandomizedSearchCV or Grid, resets after every training cycle\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.model.set_weights(self.best_weights)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "\n",
    "        def stop_train(epoch):\n",
    "            print(\"\\t > Restoring model weights from the end of the best epoch.\")\n",
    "            self.stopped_epoch = epoch\n",
    "            self.model.stop_training = True\n",
    "            self.model.set_weights(self.best_weights) \n",
    "\n",
    "        current = logs.get(self.mode)\n",
    "        x, y = self.test_data\n",
    "        test_loss, test_acc = self.model.evaluate(x, y, verbose=0)\n",
    "        \n",
    "        print()\n",
    "        print(\"\\t > Validation best %s: %s\" % (self.mode, self.best))\n",
    "        print(\"\\t > Testing loss: %s, acc: %s\" % (test_loss, test_acc))\n",
    "        print(\"\\t > Epochs since last improvement: %s\" % self.wait)\n",
    "                \n",
    "        if (self.mode == \"loss\" and np.less(test_loss, self.threshold)) or \\\n",
    "        (self.mode == \"acc\" and np.greater(test_acc, self.threshold)):\n",
    "            print(\"\\n\\t > Threshold reached.\")\n",
    "            stop_train(epoch)\n",
    "        \n",
    "        if (self.mode == \"loss\" and np.less(current, self.best)) or \\\n",
    "        (self.mode == \"acc\" and np.greater(current, self.best)):\n",
    "            print(\"\\t > Setting new best values.\")\n",
    "            self.best = current\n",
    "            self.wait = 0\n",
    "            # Record the best weights if current results is better (more).\n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                print(\"\\t > No patience.\")\n",
    "                stop_train(epoch)\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print(\"\\n\\t > Epoch %05d: early stopping\" % (self.stopped_epoch + 1))\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(patience=10),\n",
    "    EarlyStoppingAtMode((X_test, y_test), \"acc\", 0.95, 50)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n",
    "#TODO: InvalidArgumentError: Received a label value of 9\n",
    "#which is outside the valid range of [0, 9).  Label values: [...]\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "rnd_search_cv = RandomizedSearchCV(\n",
    "    keras_reg, param_distribs, n_iter=10, cv=3, verbose=2\n",
    ")\n",
    "history = rnd_search_cv.fit(X_train, y_train,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  epochs=10, steps_per_epoch=5,\n",
    "                  batch_size=64, shuffle=True,\n",
    "                  callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
